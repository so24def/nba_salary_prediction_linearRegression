{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f318509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math , copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "671ce6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Stats_from</th>\n",
       "      <th>Age</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PER</th>\n",
       "      <th>TOPG</th>\n",
       "      <th>PFG</th>\n",
       "      <th>2017_2018 Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quincy Acy</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.287304</td>\n",
       "      <td>-0.963811</td>\n",
       "      <td>-0.834424</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>-1.081728</td>\n",
       "      <td>-0.262381</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-1.014346</td>\n",
       "      <td>0.263455</td>\n",
       "      <td>-0.348183</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>-0.337766</td>\n",
       "      <td>1.331825</td>\n",
       "      <td>1.737947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arron Afflalo</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.924431</td>\n",
       "      <td>1.240197</td>\n",
       "      <td>0.510925</td>\n",
       "      <td>-0.771221</td>\n",
       "      <td>-0.205984</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>-0.806942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alexis Ajinca</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.197390</td>\n",
       "      <td>-0.994023</td>\n",
       "      <td>-0.699399</td>\n",
       "      <td>-0.162314</td>\n",
       "      <td>-0.506993</td>\n",
       "      <td>0.541693</td>\n",
       "      <td>-0.474272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.197390</td>\n",
       "      <td>-1.143741</td>\n",
       "      <td>-0.787815</td>\n",
       "      <td>1.412445</td>\n",
       "      <td>-0.316834</td>\n",
       "      <td>0.611292</td>\n",
       "      <td>-0.178865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Joe Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.771999</td>\n",
       "      <td>-1.615213</td>\n",
       "      <td>-1.090642</td>\n",
       "      <td>-0.981189</td>\n",
       "      <td>-0.645615</td>\n",
       "      <td>-1.814225</td>\n",
       "      <td>-0.915249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Nick Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.924431</td>\n",
       "      <td>-0.454942</td>\n",
       "      <td>-0.470467</td>\n",
       "      <td>-1.149164</td>\n",
       "      <td>-0.958740</td>\n",
       "      <td>-1.517006</td>\n",
       "      <td>-0.445188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.197390</td>\n",
       "      <td>1.190077</td>\n",
       "      <td>0.916875</td>\n",
       "      <td>0.614567</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>0.881372</td>\n",
       "      <td>0.768220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.771999</td>\n",
       "      <td>0.159638</td>\n",
       "      <td>-0.208376</td>\n",
       "      <td>0.320612</td>\n",
       "      <td>-0.486582</td>\n",
       "      <td>1.342569</td>\n",
       "      <td>0.488747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Tyler Zeller</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>-0.044957</td>\n",
       "      <td>-1.321992</td>\n",
       "      <td>-0.681595</td>\n",
       "      <td>0.173634</td>\n",
       "      <td>-0.693605</td>\n",
       "      <td>-0.459941</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player  Stats_from       Age       MPG       PPG       PER  \\\n",
       "0        Quincy Acy      2016.0 -0.287304 -0.963811 -0.834424  0.026657   \n",
       "1      Steven Adams      2016.0 -1.014346  0.263455 -0.348183  0.194631   \n",
       "2     Arron Afflalo      2016.0  0.924431  1.240197  0.510925 -0.771221   \n",
       "3     Alexis Ajinca      2016.0  0.197390 -0.994023 -0.699399 -0.162314   \n",
       "4      Cole Aldrich      2016.0  0.197390 -1.143741 -0.787815  1.412445   \n",
       "..              ...         ...       ...       ...       ...       ...   \n",
       "340       Joe Young      2016.0 -0.771999 -1.615213 -1.090642 -0.981189   \n",
       "341      Nick Young      2016.0  0.924431 -0.454942 -0.470467 -1.149164   \n",
       "342  Thaddeus Young      2016.0  0.197390  1.190077  0.916875  0.614567   \n",
       "343     Cody Zeller      2016.0 -0.771999  0.159638 -0.208376  0.320612   \n",
       "344    Tyler Zeller      2016.0 -0.044957 -1.321992 -0.681595  0.173634   \n",
       "\n",
       "         TOPG       PFG  2017_2018 Salary  \n",
       "0   -1.081728 -0.262381         -0.885161  \n",
       "1   -0.337766  1.331825          1.737947  \n",
       "2   -0.205984  0.126687         -0.806942  \n",
       "3   -0.506993  0.541693         -0.474272  \n",
       "4   -0.316834  0.611292         -0.178865  \n",
       "..        ...       ...               ...  \n",
       "340 -0.645615 -1.814225         -0.915249  \n",
       "341 -0.958740 -1.517006         -0.445188  \n",
       "342  0.683300  0.881372          0.768220  \n",
       "343 -0.486582  1.342569          0.488747  \n",
       "344 -0.693605 -0.459941         -0.885161  \n",
       "\n",
       "[345 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba = pd.read_csv('vised_zscaled_nba_stats_salaries_2017_2018.csv')\n",
    "\n",
    "nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e4613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>MPG</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PER</th>\n",
       "      <th>TOPG</th>\n",
       "      <th>PFG</th>\n",
       "      <th>2017_2018 Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.287304</td>\n",
       "      <td>-0.963811</td>\n",
       "      <td>-0.834424</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>-1.081728</td>\n",
       "      <td>-0.262381</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.014346</td>\n",
       "      <td>0.263455</td>\n",
       "      <td>-0.348183</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>-0.337766</td>\n",
       "      <td>1.331825</td>\n",
       "      <td>1.737947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924431</td>\n",
       "      <td>1.240197</td>\n",
       "      <td>0.510925</td>\n",
       "      <td>-0.771221</td>\n",
       "      <td>-0.205984</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>-0.806942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197390</td>\n",
       "      <td>-0.994023</td>\n",
       "      <td>-0.699399</td>\n",
       "      <td>-0.162314</td>\n",
       "      <td>-0.506993</td>\n",
       "      <td>0.541693</td>\n",
       "      <td>-0.474272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.197390</td>\n",
       "      <td>-1.143741</td>\n",
       "      <td>-0.787815</td>\n",
       "      <td>1.412445</td>\n",
       "      <td>-0.316834</td>\n",
       "      <td>0.611292</td>\n",
       "      <td>-0.178865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.771999</td>\n",
       "      <td>-1.615213</td>\n",
       "      <td>-1.090642</td>\n",
       "      <td>-0.981189</td>\n",
       "      <td>-0.645615</td>\n",
       "      <td>-1.814225</td>\n",
       "      <td>-0.915249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.924431</td>\n",
       "      <td>-0.454942</td>\n",
       "      <td>-0.470467</td>\n",
       "      <td>-1.149164</td>\n",
       "      <td>-0.958740</td>\n",
       "      <td>-1.517006</td>\n",
       "      <td>-0.445188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.197390</td>\n",
       "      <td>1.190077</td>\n",
       "      <td>0.916875</td>\n",
       "      <td>0.614567</td>\n",
       "      <td>0.683300</td>\n",
       "      <td>0.881372</td>\n",
       "      <td>0.768220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.771999</td>\n",
       "      <td>0.159638</td>\n",
       "      <td>-0.208376</td>\n",
       "      <td>0.320612</td>\n",
       "      <td>-0.486582</td>\n",
       "      <td>1.342569</td>\n",
       "      <td>0.488747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-0.044957</td>\n",
       "      <td>-1.321992</td>\n",
       "      <td>-0.681595</td>\n",
       "      <td>0.173634</td>\n",
       "      <td>-0.693605</td>\n",
       "      <td>-0.459941</td>\n",
       "      <td>-0.885161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age       MPG       PPG       PER      TOPG       PFG  \\\n",
       "0   -0.287304 -0.963811 -0.834424  0.026657 -1.081728 -0.262381   \n",
       "1   -1.014346  0.263455 -0.348183  0.194631 -0.337766  1.331825   \n",
       "2    0.924431  1.240197  0.510925 -0.771221 -0.205984  0.126687   \n",
       "3    0.197390 -0.994023 -0.699399 -0.162314 -0.506993  0.541693   \n",
       "4    0.197390 -1.143741 -0.787815  1.412445 -0.316834  0.611292   \n",
       "..        ...       ...       ...       ...       ...       ...   \n",
       "340 -0.771999 -1.615213 -1.090642 -0.981189 -0.645615 -1.814225   \n",
       "341  0.924431 -0.454942 -0.470467 -1.149164 -0.958740 -1.517006   \n",
       "342  0.197390  1.190077  0.916875  0.614567  0.683300  0.881372   \n",
       "343 -0.771999  0.159638 -0.208376  0.320612 -0.486582  1.342569   \n",
       "344 -0.044957 -1.321992 -0.681595  0.173634 -0.693605 -0.459941   \n",
       "\n",
       "     2017_2018 Salary  \n",
       "0           -0.885161  \n",
       "1            1.737947  \n",
       "2           -0.806942  \n",
       "3           -0.474272  \n",
       "4           -0.178865  \n",
       "..                ...  \n",
       "340         -0.915249  \n",
       "341         -0.445188  \n",
       "342          0.768220  \n",
       "343          0.488747  \n",
       "344         -0.885161  \n",
       "\n",
       "[345 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba.drop(columns=['Player', 'Stats_from'], axis=1, inplace=True)\n",
    "\n",
    "nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d491b7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = nba['2017_2018 Salary']\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a0a7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nba_X = nba.drop('2017_2018 Salary',axis = 1)\n",
    "\n",
    "X_train = nba_X.to_numpy()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f02ac3",
   "metadata": {},
   "source": [
    "# Cost Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688486fa",
   "metadata": {},
   "source": [
    "    J(w,b) = 1/2m( f_wb(x ^ i) - y ^ i) ^ 2  ;  i = 0..m - 1\n",
    "\n",
    "    ve f_wb(x) = w * x[i] + b olmak üzere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e52528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, w, b): \n",
    "    \n",
    "    m = X.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):                                \n",
    "        f_wb_i = np.dot(X[i], w) + b           \n",
    "        cost += (f_wb_i - y[i])**2     \n",
    "    \n",
    "    cost /= (2 * m)                      \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59e2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2898014793280912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_test = 0.2\n",
    "w_test = np.array([0.1 , 0.2 , 0.22 , 0.5 , -0.025 , -0.01])\n",
    "compute_cost(X_train,y_train,w_test,b_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42164bad",
   "metadata": {},
   "source": [
    "# Gradient Descent Algoritması:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28993eaf",
   "metadata": {},
   "source": [
    "yakınsama olana kadar tekrar et : {\n",
    "\n",
    "    w_j = w_j - a * (dJ(w,b) / dw_j)  ; j = 0..n - 1 (n = feature sayısı , a = learning rate alpha)\n",
    "\n",
    "    b = b - a * (dJ(w,b) / db)                     (w_j ve b aynı anda update edilecek(simultaneously))\n",
    "\n",
    "}\n",
    "\n",
    "ve \n",
    "\n",
    "    (dJ(w,b) / dw_j) = 1/m( f_wb(x ^ i) - y ^ i)x_j ^ i  ; i = 0..m - 1\n",
    "\n",
    "    (dJ(w,b) / db) =  1/m( f_wb(x ^ i) - y ^ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "954e0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent formüllerindeki türevli kısımları hesaplar\n",
    "\n",
    "def compute_gradient_derivatives(X, y, w, b): \n",
    "   \n",
    "    m,n = X.shape           \n",
    "    dj_dw = np.zeros((n,))  # J nin w ye göre kısmi türevi\n",
    "    dj_db = 0.              # J nin b ye göre kısmi türevi\n",
    "\n",
    "    for i in range(m):                             \n",
    "        \n",
    "        error = (np.dot(X[i], w) + b) - y[i]  \n",
    "        \n",
    "        for j in range(n):                         \n",
    "            \n",
    "            dj_dw[j] = dj_dw[j] + error * X[i, j]    \n",
    "            \n",
    "        dj_db = dj_db + error  \n",
    "        \n",
    "    dj_dw = dj_dw / m\n",
    "    \n",
    "    dj_db = dj_db / m  \n",
    "                                    \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5abf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19999999999999993,\n",
       " array([ 0.08080617, -0.05162175,  0.00049955,  0.17372699,  0.00215126,\n",
       "        -0.00789069]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient_derivatives(X_train,y_train,w_test,b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9a1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent ile J yi minimize edecek w,b değerlerini bulur, iterasyon sayısını ve w,b geçmişini gösterir\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, compute_gradient_derivatives, alpha, num_iters): \n",
    "    \n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #fonksiyondaki global w değişkenin değiştirmemek için\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Türevleri hesapla ve ata\n",
    "        dj_db,dj_dw = compute_gradient_derivatives(X, y, w, b)\n",
    "\n",
    "        # Gradient Descent Algoritması, eş zamanlı update ediliyor\n",
    "        w = w - alpha * dj_dw             \n",
    "        b = b - alpha * dj_db\n",
    "      \n",
    "        # Her iterasyon sonrası cost değerlerini kaydet\n",
    "        if i<100000:      # sınırlama \n",
    "            J_history.append(cost_function(X, y, w, b))\n",
    "\n",
    "        # yapılacak iterasyon sayısının 10'da 1'ine gelince J_history'nin son elemanını yazdır\n",
    "        if i% math.ceil(num_iters / 10) == 0:  \n",
    "            print(f\"Iteration {i:}: Cost {J_history[-1]:}   \")\n",
    "        \n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ac70b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost 0.4834028031299344   \n",
      "Iteration 100: Cost 0.2498703343180957   \n",
      "Iteration 200: Cost 0.24493996922060038   \n",
      "Iteration 300: Cost 0.24261342491483115   \n",
      "Iteration 400: Cost 0.2413145875892021   \n",
      "Iteration 500: Cost 0.24053721665385489   \n",
      "Iteration 600: Cost 0.24005626085250842   \n",
      "Iteration 700: Cost 0.23975374027910432   \n",
      "Iteration 800: Cost 0.23956151788779184   \n",
      "Iteration 900: Cost 0.2394383346302813   \n",
      "b,w found by gradient descent: 5.5335768173744554e-17,[ 0.01529997  0.28408847  0.34926467  0.22092324 -0.05261841 -0.00259832] \n",
      "prediction: -0.5061484898768139, target value: -0.8851608008511882\n",
      "prediction: -0.004972407630803005, target value: 1.7379468038539274\n",
      "prediction: 0.3850463165261524, target value: -0.8069422504090998\n",
      "prediction: -0.5342350732074809, target value: -0.4742719130844986\n",
      "prediction: -0.26993466784820846, target value: -0.1788646519326076\n",
      "prediction: 1.1308720468609708, target value: 1.6102302078119914\n",
      "prediction: -0.06206944698790311, target value: -0.8336879425965464\n",
      "prediction: 0.10671828364867661, target value: -0.1764597796349933\n",
      "prediction: -0.8155128167844069, target value: -0.901597316542022\n",
      "prediction: -0.6251898269573388, target value: -0.829297771466008\n"
     ]
    }
   ],
   "source": [
    "w_init = np.zeros(6)\n",
    "b_init = 0\n",
    "iterations = 1000\n",
    "alpha = 0.01\n",
    "\n",
    "w_final , b_final , J_hist = gradient_descent(\n",
    "                X_train, y_train, w_init, b_init , compute_cost, compute_gradient_derivatives, alpha, iterations)\n",
    "\n",
    "print(f\"b,w found by gradient descent: {b_final},{w_final} \")\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc886771",
   "metadata": {},
   "source": [
    "# Sonuç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efe5c3",
   "metadata": {},
   "source": [
    "    Data lineer regresyona pek uygun olmamasına rağmen devam etmek ve özelliklerin katsayılarını yorumlamak istedim. Farklı learning rate ler, farklı iterasyon sayıları denememe rağmen çok isabetli tahminler elde edemedim beklendiği üzere.\n",
    "\n",
    "    Pozitif katsayılar büyükten küçüğe : PPG > MPG > PER > Age --> Buradan maaşlara en çok etkisi olan özelliklerin sırasıyla 'Maç başına atılan sayı' , 'Maç başına alınan süre' , 'Oyuncu verimlilik puanı' ve 'Yaş' olduğu söylenebilir.\n",
    "\n",
    "    Negatif özelliklerde ise ; 'PFG' katsayısı 'TOPG' e kıyasla daha fazla olduğu için, maç başına yapılan faullerin maaşlara top kayıplarına göre daha çok etki ettiği söylenebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ea594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
